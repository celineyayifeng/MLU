{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLU Logo](https://drive.corp.amazon.com/view/bwernes@/MLU_Logo.png?download=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"0\">Machine Learning Accelerator - Tabular Data - Lecture 2</a>\n",
    "\n",
    "## SageMaker built-in KNN Algorithm \n",
    "\n",
    "### Sample Problem: Detecting Products with Electrical Plugs in Amazon Marketplace Products\n",
    "\n",
    "In this notebook, we use Sagemaker's built-in [KNN](https://docs.aws.amazon.com/sagemaker/latest/dg/k-nearest-neighbors.html) algorithm to predict the __target_label__ field (plug or no plug) of the Amazon electric plug dataset. \n",
    "\n",
    "\n",
    "1. <a href=\"#1\">Read the datasets</a>\n",
    "2. <a href=\"#2\">Data Processing</a>\n",
    "    * <a href=\"#21\">Exploratory Data Analysis</a>\n",
    "    * <a href=\"#22\">Select features to build the model</a>\n",
    "    * <a href=\"#23\">Data Preprocessing (cleaning)</a>\n",
    "    * <a href=\"#24\">Train - Test Datasets</a>\n",
    "    * <a href=\"#25\">Data processing with Pipeline and ColumnTransformer</a>\n",
    "3. <a href=\"#3\">Train a Classifier with SageMaker built-in Algorithm</a>\n",
    "4. <a href=\"#4\">Model evaluation</a>\n",
    "5. <a href=\"#5\">Deploy the model to an endpoint</a>\n",
    "6. <a href=\"#6\">Clean up model artifacts</a>\n",
    "\n",
    "\n",
    "7. <a href=\"#7\">(Optional) Hyperparameter Tuning in SageMaker</a>\n",
    "\n",
    "\n",
    "__Notes on [AWS SageMaker](https://docs.aws.amazon.com/sagemaker/index.html):__\n",
    "\n",
    "* Fully managed machine learning service, to quickly and easily get you started on building and training machine learning models - we have seen that already! Integrated Jupyter notebook instances, with easy access to data sources for exploration and analysis, abstract away many of the messy infrastructural details needed for hands-on ML - you don't have to manage servers, install libraries/dependencies, etc.!\n",
    "\n",
    "\n",
    "* Apart from building custom machine learning models in SageMaker notebooks, like we did so far, SageMaker also provides a few [built-in common machine learning algorithms](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html) (check \"SageMaker Examples\" from your SageMaker instance top menu for a complete updated list) that are optimized to run efficiently against extremely large data in a distributed environment. The trained model can then be directly deployed into a production-ready hosted environment for easy access at inference. \n",
    "\n",
    "\n",
    "__Dataset schema:__ \n",
    "- __ASIN__: Product ASIN\n",
    "- __target_label:__ Binary field with values in {0,1}. A value of 1 show ASIN has a plug, otherwise 0.\n",
    "- __ASIN_STATIC_ITEM_NAME:__ Title of the ASIN.\n",
    "- __ASIN_STATIC_PRODUCT_DESCRIPTION:__ Description of the ASIN\n",
    "- __ASIN_STATIC_GL_PRODUCT_GROUP_TYPE:__ GL information for the ASIN.\n",
    "- __ASIN_STATIC_ITEM_PACKAGE_WEIGHT:__ Weight of the ASIN.\n",
    "- __ASIN_STATIC_LIST_PRICE:__ Price information for the ASIN.\n",
    "- __ASIN_STATIC_BATTERIES_INCLUDED:__ Information whether batteries are included along with the product.\n",
    "- __ASIN_STATIC_BATTERIES_REQUIRED:__ Information whether batteries are required for using the product.\n",
    "- __ASIN_STATIC_ITEM_CLASSIFICATION:__ Item classification of whether it is a standalone or bundle parent item etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Read the datasets</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the training and test data files into dataframes, using [Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training dataset is: (55109, 10)\n",
      "The shape of the test dataset is: (6124, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "  \n",
    "df = pd.read_csv('../../data/review/asin_electrical_plug_training_data.csv')\n",
    "test_data = pd.read_csv('../../data/review/asin_electrical_plug_test_data.csv')\n",
    "\n",
    "print('The shape of the training dataset is:', df.shape)\n",
    "print('The shape of the test dataset is:', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a name=\"2\">Data Processing</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "### 2.1 <a name=\"21\">Exploratory Data Analysis</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "We look at number of rows, columns, and some simple statistics of the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIN</th>\n",
       "      <th>target_label</th>\n",
       "      <th>ASIN_STATIC_ITEM_NAME</th>\n",
       "      <th>ASIN_STATIC_PRODUCT_DESCRIPTION</th>\n",
       "      <th>ASIN_STATIC_GL_PRODUCT_GROUP_TYPE</th>\n",
       "      <th>ASIN_STATIC_ITEM_PACKAGE_WEIGHT</th>\n",
       "      <th>ASIN_STATIC_LIST_PRICE</th>\n",
       "      <th>ASIN_STATIC_BATTERIES_INCLUDED</th>\n",
       "      <th>ASIN_STATIC_BATTERIES_REQUIRED</th>\n",
       "      <th>ASIN_STATIC_ITEM_CLASSIFICATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000816IUC</td>\n",
       "      <td>0</td>\n",
       "      <td>Bruder 02921 Jeep Wrangler Unlimited with Hors...</td>\n",
       "      <td>NEW! Jeep Wrangler by Bruder with trailer come...</td>\n",
       "      <td>gl_toy</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>36.66</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>base_product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B003674A1Y</td>\n",
       "      <td>0</td>\n",
       "      <td>Lucky Reptile OV-2 OpenAir Vivarium, Medium</td>\n",
       "      <td>Größe: 40x40x60 cm. &lt;p&gt;Lucky Reptile OpenAir V...</td>\n",
       "      <td>gl_pet_products</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>24.68</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>base_product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B007ECONV4</td>\n",
       "      <td>0</td>\n",
       "      <td>Klarfit KS5DG Chin Up Bar (150kg Max Load, Doo...</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;Highly flexible pull-up bar with six con...</td>\n",
       "      <td>gl_sports</td>\n",
       "      <td>8.112928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>base_product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00D89465A</td>\n",
       "      <td>0</td>\n",
       "      <td>Liverpool FC Stripe Wallpaper</td>\n",
       "      <td>This fantastic Liverpool Wallpaper is ideal fo...</td>\n",
       "      <td>gl_home</td>\n",
       "      <td>1.763680</td>\n",
       "      <td>8.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B001MJ0BN4</td>\n",
       "      <td>0</td>\n",
       "      <td>Rolson 68889 Oil Tanned Double Tool Pouch</td>\n",
       "      <td>Eleven pockets, two fixed metal hammer holders...</td>\n",
       "      <td>gl_biss</td>\n",
       "      <td>2.733704</td>\n",
       "      <td>27.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ASIN  target_label  \\\n",
       "0  B000816IUC             0   \n",
       "1  B003674A1Y             0   \n",
       "2  B007ECONV4             0   \n",
       "3  B00D89465A             0   \n",
       "4  B001MJ0BN4             0   \n",
       "\n",
       "                               ASIN_STATIC_ITEM_NAME  \\\n",
       "0  Bruder 02921 Jeep Wrangler Unlimited with Hors...   \n",
       "1        Lucky Reptile OV-2 OpenAir Vivarium, Medium   \n",
       "2  Klarfit KS5DG Chin Up Bar (150kg Max Load, Doo...   \n",
       "3                      Liverpool FC Stripe Wallpaper   \n",
       "4          Rolson 68889 Oil Tanned Double Tool Pouch   \n",
       "\n",
       "                     ASIN_STATIC_PRODUCT_DESCRIPTION  \\\n",
       "0  NEW! Jeep Wrangler by Bruder with trailer come...   \n",
       "1  Größe: 40x40x60 cm. <p>Lucky Reptile OpenAir V...   \n",
       "2  <p><b>Highly flexible pull-up bar with six con...   \n",
       "3  This fantastic Liverpool Wallpaper is ideal fo...   \n",
       "4  Eleven pockets, two fixed metal hammer holders...   \n",
       "\n",
       "  ASIN_STATIC_GL_PRODUCT_GROUP_TYPE  ASIN_STATIC_ITEM_PACKAGE_WEIGHT  \\\n",
       "0                            gl_toy                         3.450000   \n",
       "1                   gl_pet_products                         2.690000   \n",
       "2                         gl_sports                         8.112928   \n",
       "3                           gl_home                         1.763680   \n",
       "4                           gl_biss                         2.733704   \n",
       "\n",
       "   ASIN_STATIC_LIST_PRICE ASIN_STATIC_BATTERIES_INCLUDED  \\\n",
       "0                   36.66                          False   \n",
       "1                   24.68                          False   \n",
       "2                     NaN                          False   \n",
       "3                    8.33                            NaN   \n",
       "4                   27.38                            NaN   \n",
       "\n",
       "  ASIN_STATIC_BATTERIES_REQUIRED ASIN_STATIC_ITEM_CLASSIFICATION  \n",
       "0                          False                    base_product  \n",
       "1                          False                    base_product  \n",
       "2                          False                    base_product  \n",
       "3                            NaN                    base_product  \n",
       "4                            NaN                    base_product  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first five rows\n",
    "# NaN means missing data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is: (55109, 10)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the dataset is:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55109 entries, 0 to 55108\n",
      "Data columns (total 10 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   ASIN                               55109 non-null  object \n",
      " 1   target_label                       55109 non-null  int64  \n",
      " 2   ASIN_STATIC_ITEM_NAME              55109 non-null  object \n",
      " 3   ASIN_STATIC_PRODUCT_DESCRIPTION    31727 non-null  object \n",
      " 4   ASIN_STATIC_GL_PRODUCT_GROUP_TYPE  55109 non-null  object \n",
      " 5   ASIN_STATIC_ITEM_PACKAGE_WEIGHT    55027 non-null  float64\n",
      " 6   ASIN_STATIC_LIST_PRICE             41182 non-null  float64\n",
      " 7   ASIN_STATIC_BATTERIES_INCLUDED     45016 non-null  object \n",
      " 8   ASIN_STATIC_BATTERIES_REQUIRED     40688 non-null  object \n",
      " 9   ASIN_STATIC_ITEM_CLASSIFICATION    55097 non-null  object \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Let's see the data types and non-null values for each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_label</th>\n",
       "      <th>ASIN_STATIC_ITEM_PACKAGE_WEIGHT</th>\n",
       "      <th>ASIN_STATIC_LIST_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>55109.000000</td>\n",
       "      <td>55027.000000</td>\n",
       "      <td>4.118200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.036618</td>\n",
       "      <td>31.130529</td>\n",
       "      <td>1.563334e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.187825</td>\n",
       "      <td>458.771422</td>\n",
       "      <td>1.754345e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.160000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>1.667000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.513244</td>\n",
       "      <td>3.268500e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.555592</td>\n",
       "      <td>6.999000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>29500.000000</td>\n",
       "      <td>3.560000e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_label  ASIN_STATIC_ITEM_PACKAGE_WEIGHT  ASIN_STATIC_LIST_PRICE\n",
       "count  55109.000000                     55027.000000            4.118200e+04\n",
       "mean       0.036618                        31.130529            1.563334e+02\n",
       "std        0.187825                       458.771422            1.754345e+04\n",
       "min        0.000000                         0.000000            1.160000e+00\n",
       "25%        0.000000                         1.520000            1.667000e+01\n",
       "50%        0.000000                         2.513244            3.268500e+01\n",
       "75%        0.000000                         5.555592            6.999000e+01\n",
       "max        1.000000                     29500.000000            3.560000e+06"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will print basic statistics for numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target distribution\n",
    "\n",
    "Let's check our target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['target_label'].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that we are dealing with an imbalanced dataset. This means one result type is dominating the other one(s). In this case, we have a lot of class 0 (\"no plug\") records and very few class 1 (\"plug\") records. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset features\n",
    "\n",
    "Let's now print the features of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dataset columns:\n",
      "['ASIN' 'target_label' 'ASIN_STATIC_ITEM_NAME'\n",
      " 'ASIN_STATIC_PRODUCT_DESCRIPTION' 'ASIN_STATIC_GL_PRODUCT_GROUP_TYPE'\n",
      " 'ASIN_STATIC_ITEM_PACKAGE_WEIGHT' 'ASIN_STATIC_LIST_PRICE'\n",
      " 'ASIN_STATIC_BATTERIES_INCLUDED' 'ASIN_STATIC_BATTERIES_REQUIRED'\n",
      " 'ASIN_STATIC_ITEM_CLASSIFICATION']\n",
      "Numerical columns:\n",
      "['target_label' 'ASIN_STATIC_ITEM_PACKAGE_WEIGHT' 'ASIN_STATIC_LIST_PRICE']\n",
      "Categorical columns:\n",
      "['ASIN' 'ASIN_STATIC_ITEM_NAME' 'ASIN_STATIC_PRODUCT_DESCRIPTION'\n",
      " 'ASIN_STATIC_GL_PRODUCT_GROUP_TYPE' 'ASIN_STATIC_BATTERIES_INCLUDED'\n",
      " 'ASIN_STATIC_BATTERIES_REQUIRED' 'ASIN_STATIC_ITEM_CLASSIFICATION']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                    \n",
    "# use this for datasets with more columns, to print all columns\n",
    "# (beware, if might raise memory errors when trying to print the text features values!)\n",
    "# np.set_printoptions(threshold=np.inf) \n",
    "\n",
    "# This prints the column labels of the dataframe\n",
    "print('All dataset columns:')\n",
    "print(df.columns.values)\n",
    "\n",
    "# This prints the column labels of the features identified as numerical\n",
    "print('Numerical columns:')\n",
    "print(df.select_dtypes(include=np.number).columns.values)\n",
    "\n",
    "# This prints the column labels of the features identified as numerical\n",
    "print('Categorical columns:')\n",
    "print(df.select_dtypes(include='object').columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 <a name=\"22\">Select features to build the model</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "We build a model using all features (except __ASIN__). That is, we build a classifier including __numerical, categorical__ and __text__ features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab model features/inputs and target/output\n",
    "numerical_features = [\"ASIN_STATIC_ITEM_PACKAGE_WEIGHT\",\n",
    "                      \"ASIN_STATIC_LIST_PRICE\"]\n",
    "\n",
    "categorical_features = ['ASIN_STATIC_GL_PRODUCT_GROUP_TYPE',\n",
    "               'ASIN_STATIC_BATTERIES_INCLUDED',\n",
    "               'ASIN_STATIC_BATTERIES_REQUIRED',\n",
    "               'ASIN_STATIC_ITEM_CLASSIFICATION']\n",
    "\n",
    "text_features = ['ASIN_STATIC_ITEM_NAME',\n",
    "                 'ASIN_STATIC_PRODUCT_DESCRIPTION']\n",
    "\n",
    "model_features = numerical_features + categorical_features + text_features\n",
    "model_target = 'target_label'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 <a name=\"23\">Data Preprocessing (Cleaning)</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "Before data processing, we first clean the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning numerical features \n",
    "\n",
    "Let's examine the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIN_STATIC_ITEM_PACKAGE_WEIGHT\n",
      "(-29.501, 2950.0]     54910\n",
      "(2950.0, 5900.0]         50\n",
      "(5900.0, 8850.0]         28\n",
      "(8850.0, 11800.0]        19\n",
      "(11800.0, 14750.0]        8\n",
      "(14750.0, 17700.0]        7\n",
      "(17700.0, 20650.0]        1\n",
      "(20650.0, 23600.0]        0\n",
      "(23600.0, 26550.0]        1\n",
      "(26550.0, 29500.0]        3\n",
      "Name: ASIN_STATIC_ITEM_PACKAGE_WEIGHT, dtype: int64\n",
      "ASIN_STATIC_LIST_PRICE\n",
      "(-3558.84, 356001.044]        41181\n",
      "(356001.044, 712000.928]          0\n",
      "(712000.928, 1068000.812]         0\n",
      "(1068000.812, 1424000.696]        0\n",
      "(1424000.696, 1780000.58]         0\n",
      "(1780000.58, 2136000.464]         0\n",
      "(2136000.464, 2492000.348]        0\n",
      "(2492000.348, 2848000.232]        0\n",
      "(2848000.232, 3204000.116]        0\n",
      "(3204000.116, 3560000.0]          1\n",
      "Name: ASIN_STATIC_LIST_PRICE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for c in numerical_features:\n",
    "    print(c)\n",
    "    print(df[c].value_counts(bins=10, sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Outliers__. We have an outlier data in the last bin of the second numerical feature. We will remove this data point below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[df[numerical_features[1]] > 3000000])\n",
    "dropIndexes = df[df[numerical_features[1]] > 3000000].index\n",
    "df.drop(dropIndexes , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-13.838999999999999, 1500.944]    41147\n",
      "(1500.944, 3000.728]                  15\n",
      "(3000.728, 4500.512]                   8\n",
      "(4500.512, 6000.296]                   3\n",
      "(6000.296, 7500.08]                    2\n",
      "(7500.08, 8999.864]                    3\n",
      "(8999.864, 10499.648]                  0\n",
      "(10499.648, 11999.432]                 1\n",
      "(11999.432, 13499.216]                 0\n",
      "(13499.216, 14999.0]                   2\n",
      "Name: ASIN_STATIC_LIST_PRICE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[numerical_features[1]].value_counts(bins=10, sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Missing Numerical Values__. Let's check missing values for these numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIN_STATIC_ITEM_PACKAGE_WEIGHT       82\n",
      "ASIN_STATIC_LIST_PRICE             13927\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[numerical_features].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick fix, we will apply mean imputation. This will replace the missing values with the mean value of the corresponding column.\n",
    "\n",
    "__Note on imputation__: The statistically correct way to perform mean/mode imputation before training an ML model is to compute the column-wise means on the training data only, and then use these values to impute missing data in the train, validation, and test sets. So, we'll need to split our training dataset first. Same goes for any other transformations we would like to apply to these numerical features, such as scaling or encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning categorical features \n",
    "\n",
    "Let's also examine the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIN_STATIC_GL_PRODUCT_GROUP_TYPE\n",
      "['gl_toy' 'gl_pet_products' 'gl_sports' 'gl_home' 'gl_biss'\n",
      " 'gl_home_improvement' 'gl_baby_product' 'gl_office_product'\n",
      " 'gl_lawn_and_garden' 'gl_musical_instruments' 'gl_camera' 'gl_kitchen'\n",
      " 'gl_automotive' 'gl_electronics' 'gl_personal_care_appliances' 'gl_pc'\n",
      " 'gl_drugstore' 'gl_luggage' 'gl_wireless' 'gl_home_entertainment'\n",
      " 'gl_major_appliances' 'gl_apparel' 'gl_beauty' 'gl_shoes' 'gl_watch'\n",
      " 'gl_video_games' 'gl_book' 'gl_music' 'gl_fresh_ambient']\n",
      "ASIN_STATIC_BATTERIES_INCLUDED\n",
      "[False nan True]\n",
      "ASIN_STATIC_BATTERIES_REQUIRED\n",
      "[False nan True]\n",
      "ASIN_STATIC_ITEM_CLASSIFICATION\n",
      "['base_product' nan 'variation_parent']\n"
     ]
    }
   ],
   "source": [
    "for c in categorical_features:\n",
    "    print(c)\n",
    "    print(df[c].unique()) #value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note on boolean type__: Most categories are strings, except the __nan__s, and the booleans __False__ and __True__. The booleans will raise errors when trying to encode the categoricals with sklearn encoders, none of which accept boolean types. If using pandas get_dummies to one-hot encode the categoricals, there's no need to convert the booleans. However, get_dummies is trickier to use with sklearn's Pipeline and GridSearch. \n",
    "\n",
    "One way to deal with the booleans is to convert them to strings, by using a mask and a map changing only the booleans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting booleans to strings for a dataframe\n",
    "def convert_bool_to_str(dataframe):\n",
    "    mask = dataframe.applymap(type) != bool\n",
    "    do = {True: 'TRUE', False: 'FALSE'}\n",
    "    return dataframe.where(mask, dataframe.replace(do))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert booleans to strings for training and test datasets\n",
    "df_masked = convert_bool_to_str(df)\n",
    "test_data_masked = convert_bool_to_str(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIN_STATIC_GL_PRODUCT_GROUP_TYPE\n",
      "['gl_toy' 'gl_pet_products' 'gl_sports' 'gl_home' 'gl_biss'\n",
      " 'gl_home_improvement' 'gl_baby_product' 'gl_office_product'\n",
      " 'gl_lawn_and_garden' 'gl_musical_instruments' 'gl_camera' 'gl_kitchen'\n",
      " 'gl_automotive' 'gl_electronics' 'gl_personal_care_appliances' 'gl_pc'\n",
      " 'gl_drugstore' 'gl_luggage' 'gl_wireless' 'gl_home_entertainment'\n",
      " 'gl_major_appliances' 'gl_apparel' 'gl_beauty' 'gl_shoes' 'gl_watch'\n",
      " 'gl_video_games' 'gl_book' 'gl_music' 'gl_fresh_ambient']\n",
      "ASIN_STATIC_BATTERIES_INCLUDED\n",
      "['FALSE' nan 'TRUE']\n",
      "ASIN_STATIC_BATTERIES_REQUIRED\n",
      "['FALSE' nan 'TRUE']\n",
      "ASIN_STATIC_ITEM_CLASSIFICATION\n",
      "['base_product' nan 'variation_parent']\n"
     ]
    }
   ],
   "source": [
    "for c in categorical_features:\n",
    "    print(c)\n",
    "    print(df_masked[c].unique()) #value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to handle the booleans is to convert them to strings by changing the type of all categoricals to 'str'. This will also affect the nans, basically performing imputation of the nans with a 'nans' placeholder value! \n",
    "\n",
    "Applying the type conversion to both categoricals and text features, takes care of the nans in the text fields as well. In case other imputations are planned for the categoricals and/or test fields, notice that the masking shown above leaves the nans unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform boolean to string operation on training and test datasets\n",
    "df[categorical_features + text_features] = df[categorical_features + text_features].astype('str')\n",
    "test_data[categorical_features + text_features] = test_data[categorical_features + text_features].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIN_STATIC_GL_PRODUCT_GROUP_TYPE\n",
      "['gl_toy' 'gl_pet_products' 'gl_sports' 'gl_home' 'gl_biss'\n",
      " 'gl_home_improvement' 'gl_baby_product' 'gl_office_product'\n",
      " 'gl_lawn_and_garden' 'gl_musical_instruments' 'gl_camera' 'gl_kitchen'\n",
      " 'gl_automotive' 'gl_electronics' 'gl_personal_care_appliances' 'gl_pc'\n",
      " 'gl_drugstore' 'gl_luggage' 'gl_wireless' 'gl_home_entertainment'\n",
      " 'gl_major_appliances' 'gl_apparel' 'gl_beauty' 'gl_shoes' 'gl_watch'\n",
      " 'gl_video_games' 'gl_book' 'gl_music' 'gl_fresh_ambient']\n",
      "ASIN_STATIC_BATTERIES_INCLUDED\n",
      "['False' 'nan' 'True']\n",
      "ASIN_STATIC_BATTERIES_REQUIRED\n",
      "['False' 'nan' 'True']\n",
      "ASIN_STATIC_ITEM_CLASSIFICATION\n",
      "['base_product' 'nan' 'variation_parent']\n"
     ]
    }
   ],
   "source": [
    "for c in categorical_features:\n",
    "    print(c)\n",
    "    print(df[c].unique()) #value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting categoricals into useful numerical features, will also have to wait until after the train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning text features \n",
    "\n",
    "Also a good idea to look at the text fields. Text cleaning can be performed here, before train/test split, with less code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c in text_features:\n",
    "#    print(c)\n",
    "#    print(df[c].unique()) #value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-use the helper functions from the 'Text processing' notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare cleaning functions\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stop_words = [\"a\", \"an\", \"the\", \"this\", \"that\", \"is\", \"it\", \"to\", \"and\"]\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def preProcessText(text):\n",
    "    # lowercase and strip leading/trailing white space\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.compile('<.*?>').sub('', text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
    "    \n",
    "    # remove extra white space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def lexiconProcess(text, stop_words, stemmer):\n",
    "    filtered_sentence = []\n",
    "    words = text.split(\" \")\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(stemmer.stem(w))\n",
    "    text = \" \".join(filtered_sentence)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def cleanSentence(text, stop_words, stemmer):\n",
    "    return lexiconProcess(preProcessText(text), stop_words, stemmer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Warning__: The text cleaning process can take a long time to complete, depending on the size of the text data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning:  ASIN_STATIC_ITEM_NAME\n",
      "Text cleaning:  ASIN_STATIC_PRODUCT_DESCRIPTION\n"
     ]
    }
   ],
   "source": [
    "# Clean the text features\n",
    "for c in text_features:\n",
    "    print('Text cleaning: ', c)\n",
    "    df[c] = [cleanSentence(item, stop_words, stemmer) for item in df[c].values]\n",
    "    test_data[c] = [cleanSentence(item, stop_words, stemmer) for item in test_data[c].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaned text features of the training and test dataset are ready to be vectorized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 <a name=\"24\">Train - Test Datasets</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "We have already split the original dataset into two data files: __training__ data file (asin_electrical_plug_training_data.csv) with __90%__ of the samples and the __test__ data file (asin_electrical_plug_test_data.csv) with the remaining __10%__. \n",
    "Such splits can be performed using sklearn's [__train_test_split()__](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Test Datasets shapes:  (55108, 10) (6124, 10)\n"
     ]
    }
   ],
   "source": [
    "# Set the training data as our df\n",
    "train_data = df\n",
    "\n",
    "# Print the shapes of the Train - Test Datasets\n",
    "print('Train - Test Datasets shapes: ', train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 <a name=\"25\">Data processing with Pipeline and ColumnTransformer</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "We use the collective __ColumnTransformer__ to preprocess the data for SageMaker model training and test, ensuring that the transformations learned on the train data are performed accordingly on the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets shapes before processing:  (55108, 8) (6124, 8)\n",
      "Datasets shapes after processing:  (55108, 240) (6124, 240)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "### COLUMN_TRANSFORMER ###\n",
    "##########################\n",
    "\n",
    "# Preprocess the numerical features\n",
    "numerical_processor = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='mean')),\n",
    "    ('num_scaler', MinMaxScaler()) # Shown in case is needed, not a must with Decision Trees\n",
    "                                ])\n",
    "                  \n",
    "# Preprocess the categorical features\n",
    "categorical_processor = Pipeline([\n",
    "    ('cat_imputer', SimpleImputer(strategy='constant', fill_value='missing')), # Shown in case is needed, no effect here as we already imputed with 'nan' strings\n",
    "    ('cat_encoder', OneHotEncoder(handle_unknown='ignore')) # handle_unknown tells it to ignore (rather than throw an error for) any value that was not present in the initial training set.\n",
    "                                ])\n",
    "\n",
    "# Preprocess 1st text feature\n",
    "text_processor_0 = Pipeline([\n",
    "    ('text_vectorizer_0', CountVectorizer(binary=True, max_features=50))\n",
    "                                ])\n",
    "\n",
    "# Preprocess 2nd text feature (larger vocabulary)\n",
    "text_processor_1 = Pipeline([\n",
    "    ('text_vectorizer_1', CountVectorizer(binary=True, max_features=150))\n",
    "                                ])\n",
    "\n",
    "# Combine all data preprocessors from above (add more, if you choose to define more!)\n",
    "# For each processor/step specify: a name, the actual process, and finally the features to be processed\n",
    "data_processor = ColumnTransformer([\n",
    "    ('numerical_processing', numerical_processor, numerical_features),\n",
    "    ('categorical_processing', categorical_processor, categorical_features),\n",
    "    ('text_processing_0', text_processor_0, text_features[0]),\n",
    "    ('text_processing_1', text_processor_1, text_features[1])\n",
    "                                    ]) \n",
    "\n",
    "# Visualize the data processing pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "data_processor\n",
    "\n",
    "### DATA PROCESSING ###\n",
    "#######################\n",
    "\n",
    "# Get train data to train the network\n",
    "X_train = train_data[model_features]\n",
    "y_train = train_data[model_target]\n",
    "\n",
    "# Get test data to test the network for submission to the leaderboard\n",
    "X_test = test_data[model_features]\n",
    "y_test = test_data[model_target]\n",
    "\n",
    "print('Datasets shapes before processing: ', X_train.shape, X_test.shape)\n",
    "\n",
    "X_train = data_processor.fit_transform(X_train).toarray()\n",
    "X_test = data_processor.transform(X_test).toarray()\n",
    "\n",
    "print('Datasets shapes after processing: ', X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a name=\"3\">Train a classifier with SageMaker built-in algorithm</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "We use Amazon SageMaker [KNN](https://docs.aws.amazon.com/sagemaker/latest/dg/k-nearest-neighbors.html) algorithm to build our classifier. We explain the components common to all Amazon SageMaker's algorithms including uploading data to Amazon S3, training a model, and setting up an endpoint for online inference. \n",
    "\n",
    "### Set up the SageMaker environment\n",
    "\n",
    "Let's start by importing libraries we need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from os import path\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload datasets to Amazon S3\n",
    "\n",
    "Amazon SageMaker [K-Nearest Neighbors (k-NN)](https://docs.aws.amazon.com/sagemaker/latest/dg/k-nearest-neighbors.html) can train on data in either a CSV or recordIO-wrapped-protobuf format.  For this example, we stick with the recordIO-wrapped-protobuf.  \n",
    "\n",
    "So, let's write the data to Amazon S3 in recordio-protobuf format. We first create an io buffer wrapping the data, next we upload it to Amazon S3. Notice that the choice of bucket and prefix should change for different users and different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features shape =  (55108, 240)\n",
      "train_labels shape =  (55108,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "print('train_features shape = ', X_train.shape)\n",
    "print('train_labels shape = ', y_train.shape)\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, X_train, y_train.values)\n",
    "buf.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://sagemaker-us-west-2-835188026949/knn-demo/train/recordio-pb-data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'knn-demo'\n",
    "key = 'recordio-pb-data'\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket).Object(\n",
    "    os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "\n",
    "print('uploaded training data location: {}'.format(s3_train_data))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to provide test data. This way we can get an test of the performance of the model from the training logs. In order to use this capability let's upload the test data to Amazon S3 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_features shape =  (6124, 240)\n",
      "test_labels shape =  (6124,)\n",
      "uploaded test data location: s3://sagemaker-us-west-2-835188026949/knn-demo/test/recordio-pb-data\n"
     ]
    }
   ],
   "source": [
    "print('test_features shape = ', X_test.shape)\n",
    "print('test_labels shape = ', y_test.shape)\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, X_test, y_test.values)\n",
    "buf.seek(0)\n",
    "    \n",
    "boto3.resource('s3').Bucket(bucket).Object(\n",
    "    os.path.join(prefix, 'test', key)).upload_fileobj(buf)\n",
    "\n",
    "s3_test_data = 's3://{}/{}/test/{}'.format(bucket, prefix, key)\n",
    "\n",
    "print('uploaded test data location: {}'.format(s3_test_data))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the classifier\n",
    "\n",
    "We use the built-in Sagemaker [K-Nearest Neighbors (k-NN)](https://docs.aws.amazon.com/sagemaker/latest/dg/k-nearest-neighbors.html) below. \n",
    "\n",
    "In Amazon SageMaker, model training is done via an object called an __estimator__. When setting up the estimator we specify the location (in Amazon S3) of the training data, the path (again in Amazon S3) to the output directory where the model will be serialized, generic hyper-parameters such as the machine type to use during the training process, and kNN-specific hyper-parameters. Once the estimator is initialized, we can call its __.fit()__ method in order to do the actual training.\n",
    "\n",
    "* __Compute power:__ We will use `train_instance_count` and `train_instance_type` parameters. This example uses `ml.m4.xlarge` resource for training. The instance_type is the machine type that will host the model. We can change the instance type for our needs (for example GPUs for neural networks).\n",
    "* __Model type:__ `predictor_type` is set to __`classifier`__, as we have a classification problem here.\n",
    "* __Hyperparameters:__ For now, we stick to default required parameters __`predictor_type`__, __`feature_dim`__, __`k`__, and __`sample_size`__. The __`sample_size`__ parameter determines how many points from the data set should be used for building the model. Using all the data points is tempting and definitely can't hurt the quality of the outputs but is often either infeasible or simply too costly. Moreover, it can often be unnecessary in the sense that you may get the same accuracy with less points. In that case, there is simply no need to build a model with all the data points. In this example we use a sample of 10K points out of the potential ~48K in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set an output path where the trained model will be saved\n",
    "output_path = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "# set required KNN hyperparameters\n",
    "hyperparams = {\n",
    "    'predictor_type': 'classifier', \n",
    "    'feature_dim': 240,\n",
    "    'k': 10,\n",
    "    'sample_size': 10000\n",
    "                }\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# Create a container with KNN\n",
    "container = sagemaker.image_uris.retrieve('knn', region)\n",
    "\n",
    "# Call the KNN estimator object\n",
    "KNN_estimator = sagemaker.estimator.Estimator(\n",
    "        container,\n",
    "        get_execution_role(),\n",
    "        hyperparameters = hyperparams,\n",
    "        instance_count=1,\n",
    "        instance_type='ml.m5.2xlarge',\n",
    "        output_path=output_path,\n",
    "        sagemaker_session=sagemaker.Session())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we run the actual training job. \n",
    "\n",
    "__Warning: This process takes about 3-4 minutes to complete on the ml.m4.xlarge instance.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: knn-2023-06-09-18-11-54-676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-09 18:11:54 Starting - Starting the training job...\n",
      "2023-06-09 18:12:18 Starting - Preparing the instances for training......\n",
      "2023-06-09 18:13:13 Downloading - Downloading input data...\n",
      "2023-06-09 18:13:33 Training - Downloading the training image......\n",
      "2023-06-09 18:14:49 Training - Training image download completed. Training in progress....\n",
      "2023-06-09 18:15:25 Uploading - Uploading generated training model\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:14 INFO 139755190437696] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'_kvstore': 'dist_async', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_tuning_objective_metric': '', '_faiss_index_nprobe': '5', 'epochs': '1', 'feature_dim': 'auto', 'faiss_index_ivf_nlists': 'auto', 'index_metric': 'L2', 'index_type': 'faiss.Flat', 'mini_batch_size': '5000', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:14 INFO 139755190437696] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '240', 'k': '10', 'predictor_type': 'classifier', 'sample_size': '10000'}\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:14 INFO 139755190437696] Final configuration: {'_kvstore': 'dist_async', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_tuning_objective_metric': '', '_faiss_index_nprobe': '5', 'epochs': '1', 'feature_dim': '240', 'faiss_index_ivf_nlists': 'auto', 'index_metric': 'L2', 'index_type': 'faiss.Flat', 'mini_batch_size': '5000', '_enable_profiler': 'false', 'k': '10', 'predictor_type': 'classifier', 'sample_size': '10000'}\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 WARNING 139755190437696] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] Final configuration: {'_kvstore': 'dist_async', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_tuning_objective_metric': '', '_faiss_index_nprobe': '5', 'epochs': '1', 'feature_dim': '240', 'faiss_index_ivf_nlists': 'auto', 'index_metric': 'L2', 'index_type': 'faiss.Flat', 'mini_batch_size': '5000', '_enable_profiler': 'false', 'k': '10', 'predictor_type': 'classifier', 'sample_size': '10000'}\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 WARNING 139755190437696] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-139-241.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'knn-2023-06-09-18-11-54-676', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:835188026949:training-job/knn-2023-06-09-18-11-54-676', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-b22c9c88104b8650b739d70dad788165127d546e76000771a84c582136f5739e-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'SAGEMAKER_MANAGED_WARMPOOL_CACHE_DIRECTORY': '/opt/ml/sagemaker/warmpoolcache', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-2', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'CUDA_VERSION': '11.1', 'HOME': '/root', 'SHLVL': '1', 'CUDA_COMPAT_NDRIVER_SUPPORTED_VERSION': '455.32.00', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '4', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE'}\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-139-241.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'knn-2023-06-09-18-11-54-676', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:835188026949:training-job/knn-2023-06-09-18-11-54-676', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-b22c9c88104b8650b739d70dad788165127d546e76000771a84c582136f5739e-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'SAGEMAKER_MANAGED_WARMPOOL_CACHE_DIRECTORY': '/opt/ml/sagemaker/warmpoolcache', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-2', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'CUDA_VERSION': '11.1', 'HOME': '/root', 'SHLVL': '1', 'CUDA_COMPAT_NDRIVER_SUPPORTED_VERSION': '455.32.00', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '4', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE', 'DMLC_ROLE': 'scheduler', 'DMLC_PS_ROOT_URI': '10.0.139.241', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-139-241.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'knn-2023-06-09-18-11-54-676', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:835188026949:training-job/knn-2023-06-09-18-11-54-676', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-b22c9c88104b8650b739d70dad788165127d546e76000771a84c582136f5739e-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'SAGEMAKER_MANAGED_WARMPOOL_CACHE_DIRECTORY': '/opt/ml/sagemaker/warmpoolcache', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-2', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'CUDA_VERSION': '11.1', 'HOME': '/root', 'SHLVL': '1', 'CUDA_COMPAT_NDRIVER_SUPPORTED_VERSION': '455.32.00', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '4', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE'}\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-139-241.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'knn-2023-06-09-18-11-54-676', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:835188026949:training-job/knn-2023-06-09-18-11-54-676', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-b22c9c88104b8650b739d70dad788165127d546e76000771a84c582136f5739e-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'SAGEMAKER_MANAGED_WARMPOOL_CACHE_DIRECTORY': '/opt/ml/sagemaker/warmpoolcache', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-2', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'CUDA_VERSION': '11.1', 'HOME': '/root', 'SHLVL': '1', 'CUDA_COMPAT_NDRIVER_SUPPORTED_VERSION': '455.32.00', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '4', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE', 'DMLC_ROLE': 'server', 'DMLC_PS_ROOT_URI': '10.0.139.241', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] Environment: {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-139-241.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'knn-2023-06-09-18-11-54-676', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:835188026949:training-job/knn-2023-06-09-18-11-54-676', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-b22c9c88104b8650b739d70dad788165127d546e76000771a84c582136f5739e-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'SAGEMAKER_MANAGED_WARMPOOL_CACHE_DIRECTORY': '/opt/ml/sagemaker/warmpoolcache', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-2', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'CUDA_VERSION': '11.1', 'HOME': '/root', 'SHLVL': '1', 'CUDA_COMPAT_NDRIVER_SUPPORTED_VERSION': '455.32.00', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '4', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE', 'DMLC_ROLE': 'worker', 'DMLC_PS_ROOT_URI': '10.0.139.241', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34mProcess 40 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 49 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] Using default worker.\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] Loading faiss with AVX2 support.\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] Successfully loaded faiss with AVX2 support.\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2023-06-09 18:15:17.713] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] nvidia-smi: took 0.039 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 ERROR 139755190437696] nvidia-smi: failed to run (127): b'/bin/sh: nvidia-smi: command not found'/\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 WARNING 139755190437696] Could not determine free memory in MB for GPU device with ID (0).\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:17 INFO 139755190437696] Using per-machine sample size = 10000 (Available virtual memory = 31361888256 bytes, GPU free memory = 0 bytes, number of machines = 1). If an out-of-memory error occurs, choose a larger instance type, use dimension reduction, decrease sample_size, increase the number of instances, and/or decrease mini_batch_size.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1686334517.8176882, \"EndTime\": 1686334517.8177564, \"Dimensions\": {\"Algorithm\": \"AWS/KNN\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[2023-06-09 18:15:17.827] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 130, \"num_examples\": 1, \"num_bytes\": 9840000}\u001b[0m\n",
      "\u001b[34m[2023-06-09 18:15:18.064] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 236, \"num_examples\": 12, \"num_bytes\": 108452544}\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:18 INFO 139755190437696] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1686334517.8277328, \"EndTime\": 1686334518.0653985, \"Dimensions\": {\"Algorithm\": \"AWS/KNN\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 55108.0, \"count\": 1, \"min\": 55108, \"max\": 55108}, \"Total Batches Seen\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Max Records Seen Between Resets\": {\"sum\": 55108.0, \"count\": 1, \"min\": 55108, \"max\": 55108}, \"Max Batches Seen Between Resets\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 55108.0, \"count\": 1, \"min\": 55108, \"max\": 55108}, \"Number of Batches Since Last Reset\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}}}\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:18 INFO 139755190437696] #throughput_metric: host=algo-1, train throughput=231709.24615905897 records/second\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:18 INFO 139755190437696] Create Store: dist_async\u001b[0m\n",
      "\u001b[34m[18:15:18] ../src/base.cc:47: Please install cuda driver for GPU use.  No cuda driver detected.\u001b[0m\n",
      "\u001b[34m[18:15:18] ../src/base.cc:47: Please install cuda driver for GPU use.  No cuda driver detected.\u001b[0m\n",
      "\u001b[34m[18:15:18] ../src/base.cc:47: Please install cuda driver for GPU use.  No cuda driver detected.\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:18 INFO 139755190437696] Using in-memory reservoir sample from master machine...\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:18 INFO 139755190437696] ...Got reservoir sample from algo-1: data=(10000, 240), labels=(10000,), NaNs=0\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:18 INFO 139755190437696] Training index...\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:18 INFO 139755190437696] ...Finished training index in 0 second(s)\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:18 INFO 139755190437696] Adding data to index...\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:18 INFO 139755190437696] ...Finished adding data to index in 0 second(s)\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1686334517.6967504, \"EndTime\": 1686334518.8112128, \"Dimensions\": {\"Algorithm\": \"AWS/KNN\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 78.28259468078613, \"count\": 1, \"min\": 78.28259468078613, \"max\": 78.28259468078613}, \"epochs\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"update.time\": {\"sum\": 237.3523712158203, \"count\": 1, \"min\": 237.3523712158203, \"max\": 237.3523712158203}, \"finalize.time\": {\"sum\": 16.820192337036133, \"count\": 1, \"min\": 16.820192337036133, \"max\": 16.820192337036133}, \"model.serialize.time\": {\"sum\": 9.662389755249023, \"count\": 1, \"min\": 9.662389755249023, \"max\": 9.662389755249023}}}\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:18 INFO 139755190437696] Searching index...\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:18 INFO 139755190437696] ...Done searching index in 0 second(s)\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:19 INFO 139755190437696] Searching index...\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:19 INFO 139755190437696] ...Done searching index in 0 second(s)\u001b[0m\n",
      "\u001b[34m[2023-06-09 18:15:19.106] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 1392, \"num_examples\": 2, \"num_bytes\": 12052032}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1686334518.8117502, \"EndTime\": 1686334519.1087408, \"Dimensions\": {\"Algorithm\": \"AWS/KNN\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6124.0, \"count\": 1, \"min\": 6124, \"max\": 6124}, \"Total Batches Seen\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Max Records Seen Between Resets\": {\"sum\": 6124.0, \"count\": 1, \"min\": 6124, \"max\": 6124}, \"Max Batches Seen Between Resets\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 6124.0, \"count\": 1, \"min\": 6124, \"max\": 6124}, \"Number of Batches Since Last Reset\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}}}\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:19 INFO 139755190437696] #test_score (algo-1) : ('accuracy', 0.9630960156760288)\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:19 INFO 139755190437696] #test_score (algo-1) : ('binary_f_1.000', 0.0)\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:19 INFO 139755190437696] #test_score (algo-1) : ('roc_auc_score', 0.5)\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:19 INFO 139755190437696] #quality_metric: host=algo-1, test accuracy <score>=0.9630960156760288\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:19 INFO 139755190437696] #quality_metric: host=algo-1, test binary_f_1.000 <score>=0.0\u001b[0m\n",
      "\u001b[34m[06/09/2023 18:15:19 INFO 139755190437696] #quality_metric: host=algo-1, test roc_auc_score <score>=0.5\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1686334518.8112903, \"EndTime\": 1686334519.1106944, \"Dimensions\": {\"Algorithm\": \"AWS/KNN\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 15.449285507202148, \"count\": 1, \"min\": 15.449285507202148, \"max\": 15.449285507202148}, \"totaltime\": {\"sum\": 1738.0619049072266, \"count\": 1, \"min\": 1738.0619049072266, \"max\": 1738.0619049072266}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-06-09 18:15:36 Completed - Training job completed\n",
      "Training seconds: 143\n",
      "Billable seconds: 143\n",
      "CPU times: user 854 ms, sys: 35.6 ms, total: 890 ms\n",
      "Wall time: 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "KNN_estimator.fit({'train': s3_train_data, 'test': s3_test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a name=\"4\">Model Evaluation</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "We can use Sagemaker analytics to get the performance metric on the test set. This doesn't require us to deploy our model. AWS SageMaker [KNN](https://docs.aws.amazon.com/sagemaker/latest/dg/k-nearest-neighbors.html) computes __`test:accuracy`__ for a classification task. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>test:accuracy</td>\n",
       "      <td>0.963096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp    metric_name     value\n",
       "0        0.0  test:accuracy  0.963096"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.analytics.TrainingJobAnalytics(KNN_estimator._current_job_name, \n",
    "                                         metric_names = ['test:accuracy']\n",
    "                                        ).dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a name=\"5\">Deploy the model to an endpoint</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "\n",
    "We have successfully trained and evaluated our model. If happy with the performance, it is time to deploy the model to another instance of our choice. We set up what is called an __endpoint__. An endpoint is a web service that given a request containing an unlabeled data point, or mini-batch of data points, returns a prediction(s). This allow us to use this model in production environment. \n",
    "\n",
    "Deployed endpoints can be used with other AWS Services such as Lambda and API Gateway. A nice walkthrough is available here: https://aws.amazon.com/blogs/machine-learning/call-an-amazon-sagemaker-model-endpoint-using-amazon-api-gateway-and-aws-lambda/ if you are interested.\n",
    "\n",
    "We use a `ml.t2.medium` instance here, but can also use other instance types such as:, `ml.c4.xlarge` etc. \n",
    "\n",
    "__Warning: This process takes about 10-11 minutes to complete.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: knn-2023-06-09-18-16-11-221\n",
      "INFO:sagemaker:Creating endpoint-config with name endpoint-mla-tab-2023June9-knn\n",
      "INFO:sagemaker:Creating endpoint with name endpoint-mla-tab-2023June9-knn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------!CPU times: user 260 ms, sys: 17 ms, total: 277 ms\n",
      "Wall time: 13min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "KNN_predictor = KNN_estimator.deploy(initial_instance_count=1, \n",
    "                                     instance_type=\"ml.t2.medium\", \n",
    "                                     endpoint_name=\"endpoint-mla-tab-2023June9-knn\") # endpoint_name needs to be unique!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. <a name=\"6\">Clean up model artifacts</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "__If you're ready to be done with this notebook, please run the cell below. This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: endpoint-mla-tab-2023June9-knn\n",
      "INFO:sagemaker:Deleting endpoint with name: endpoint-mla-tab-2023June9-knn\n"
     ]
    }
   ],
   "source": [
    "KNN_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. <a name=\"7\">(Optional) Hyperparameter Tuning in SageMaker with the Python SDK</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Automatic model tuning, finds the best version of a model by running many jobs that test a range of hyperparameters on your dataset. We choose the tunable hyperparameters, a range of values for each, and an objective metric. Objective metrics are chosen from the metrics that the algorithm computes. AWS SageMaker [KNN](https://docs.aws.amazon.com/sagemaker/latest/dg/k-nearest-neighbors.html) computes __`test:accuracy`__ for a classification task. \n",
    "\n",
    "We tune AWS SageMaker [KNN](https://docs.aws.amazon.com/sagemaker/latest/dg/kNN-tuning.html) with the following hyperparameters: __`k`__ and __`sample_size`__. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "# Recreate the Estimator from above\n",
    "\n",
    "# set an output path where the trained model will be saved\n",
    "output_path = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "# set required KNN hyperparameters\n",
    "hyperparams = {\n",
    "    'predictor_type': 'classifier', \n",
    "    'feature_dim': 240,\n",
    "    'k': 10,\n",
    "    'sample_size': 10000\n",
    "                }\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# Call the KNN estimator object\n",
    "KNN_estimator = sagemaker.estimator.Estimator(\n",
    "        sagemaker.image_uris.retrieve('knn', region),\n",
    "        get_execution_role(),\n",
    "        hyperparameters = hyperparams,\n",
    "        instance_count=1,\n",
    "        instance_type='ml.m5.2xlarge',\n",
    "        output_path=output_path,\n",
    "        sagemaker_session=sagemaker.Session())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the hyperparameters we'd like to tune and their possible values. We have three different types of hyperparameters.\n",
    "   * __Categorical parameters__ need to take one value from a discrete set. We define this by passing the list of possible values to CategoricalParameter(list)\n",
    "   * __Continuous parameters__ can take any real number value between the minimum and maximum value, defined by ContinuousParameter(min, max)\n",
    "   * __Integer parameters__ can take any integer value between the minimum and maximum value, defined by IntegerParameter(min, max)\n",
    "\n",
    "*Note, if possible, it's almost always best to specify a value as the least restrictive type. For example, tuning threshold as a continuous value between 0.01 and 0.2 is likely to yield a better result than tuning as a categorical parameter with possible values of 0.01, 0.1, 0.15, or 0.2.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter\n",
    "\n",
    "# Define exploration boundaries\n",
    "hyperparameter_ranges = {\n",
    "                        'k': IntegerParameter(1, 10),\n",
    "                        'sample_size': IntegerParameter(2560, 10000)\n",
    "                        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a __HyperparameterTuner__ object, to which we pass:\n",
    "\n",
    "* The __estimator__ we created above\n",
    "* Our __hyperparameter ranges__ \n",
    "* __objective metric name__, that is the objective metric that we'd like to tune\n",
    "* __objective type__: whether we should maximize or minimize our objective metric (we haven't specified here since it defaults to 'Maximize', which is what we want for test accuracy)\n",
    "* __max_jobs__: number of training jobs to run in total\n",
    "* __max_parallel_jobs__: how many training jobs should be run simultaneously\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "# create tuner\n",
    "KNN_tuner = HyperparameterTuner(estimator=KNN_estimator,\n",
    "                            objective_metric_name='test:accuracy',\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            objective_type='Maximize',\n",
    "                            max_jobs=9,\n",
    "                            max_parallel_jobs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can start our tuning job by calling __.fit()__ and passing in the S3 paths to our train and test datasets.\n",
    "\n",
    "__Warning: This this step may take 13-14 minutes to complete.__ Even if you loose connection with the notebook in the middle, as long as the notebook instance continues to run, jobs should still be successfully created for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: knn-230609-1829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................!\n",
      "!\n",
      "CPU times: user 413 ms, sys: 39.9 ms, total: 453 ms\n",
      "Wall time: 7min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "KNN_tuner.fit({'train': s3_train_data, 'test': s3_test_data})\n",
    "KNN_tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just run a quick check of the hyperparameter tuning jobs status to make sure it started successfully and is `InProgress`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=KNN_tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: You will be unable to successfully run the following cells until the tuning job completes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      k  sample_size               TrainingJobName TrainingJobStatus  \\\n",
      "0   7.0       9788.0  knn-230609-1829-009-04394ea8         Completed   \n",
      "1   6.0       7278.0  knn-230609-1829-008-6212a6c0         Completed   \n",
      "2   5.0       6002.0  knn-230609-1829-007-1ade3091         Completed   \n",
      "3   9.0       8388.0  knn-230609-1829-006-7338c7f4         Completed   \n",
      "4  10.0       9448.0  knn-230609-1829-005-76c7857c         Completed   \n",
      "5   1.0       7323.0  knn-230609-1829-004-db825a9b         Completed   \n",
      "6   8.0       6980.0  knn-230609-1829-003-88f0c586         Completed   \n",
      "7   4.0       8614.0  knn-230609-1829-002-e64bd444         Completed   \n",
      "8  10.0       6702.0  knn-230609-1829-001-6c106582         Completed   \n",
      "\n",
      "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
      "0             0.962116 2023-06-09 18:36:18+00:00 2023-06-09 18:36:50+00:00   \n",
      "1             0.962443 2023-06-09 18:36:11+00:00 2023-06-09 18:36:43+00:00   \n",
      "2             0.958361 2023-06-09 18:36:09+00:00 2023-06-09 18:36:40+00:00   \n",
      "3             0.962769 2023-06-09 18:35:21+00:00 2023-06-09 18:35:52+00:00   \n",
      "4             0.962769 2023-06-09 18:35:23+00:00 2023-06-09 18:35:55+00:00   \n",
      "5             0.927825 2023-06-09 18:35:21+00:00 2023-06-09 18:35:52+00:00   \n",
      "6             0.962933 2023-06-09 18:31:17+00:00 2023-06-09 18:34:55+00:00   \n",
      "7             0.962443 2023-06-09 18:31:06+00:00 2023-06-09 18:34:54+00:00   \n",
      "8             0.962933 2023-06-09 18:31:01+00:00 2023-06-09 18:34:54+00:00   \n",
      "\n",
      "   TrainingElapsedTimeSeconds  \n",
      "0                        32.0  \n",
      "1                        32.0  \n",
      "2                        31.0  \n",
      "3                        31.0  \n",
      "4                        32.0  \n",
      "5                        31.0  \n",
      "6                       218.0  \n",
      "7                       228.0  \n",
      "8                       233.0  \n"
     ]
    }
   ],
   "source": [
    "# get tuner results in a dataframe\n",
    "results = KNN_tuner.analytics().dataframe()\n",
    "print(results.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the tuning job finishes, we can bring in a table of metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6980.0</td>\n",
       "      <td>knn-230609-1829-003-88f0c586</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.962933</td>\n",
       "      <td>2023-06-09 18:31:17+00:00</td>\n",
       "      <td>2023-06-09 18:34:55+00:00</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6702.0</td>\n",
       "      <td>knn-230609-1829-001-6c106582</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.962933</td>\n",
       "      <td>2023-06-09 18:31:01+00:00</td>\n",
       "      <td>2023-06-09 18:34:54+00:00</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8388.0</td>\n",
       "      <td>knn-230609-1829-006-7338c7f4</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.962769</td>\n",
       "      <td>2023-06-09 18:35:21+00:00</td>\n",
       "      <td>2023-06-09 18:35:52+00:00</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9448.0</td>\n",
       "      <td>knn-230609-1829-005-76c7857c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.962769</td>\n",
       "      <td>2023-06-09 18:35:23+00:00</td>\n",
       "      <td>2023-06-09 18:35:55+00:00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7278.0</td>\n",
       "      <td>knn-230609-1829-008-6212a6c0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.962443</td>\n",
       "      <td>2023-06-09 18:36:11+00:00</td>\n",
       "      <td>2023-06-09 18:36:43+00:00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8614.0</td>\n",
       "      <td>knn-230609-1829-002-e64bd444</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.962443</td>\n",
       "      <td>2023-06-09 18:31:06+00:00</td>\n",
       "      <td>2023-06-09 18:34:54+00:00</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9788.0</td>\n",
       "      <td>knn-230609-1829-009-04394ea8</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.962116</td>\n",
       "      <td>2023-06-09 18:36:18+00:00</td>\n",
       "      <td>2023-06-09 18:36:50+00:00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6002.0</td>\n",
       "      <td>knn-230609-1829-007-1ade3091</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.958361</td>\n",
       "      <td>2023-06-09 18:36:09+00:00</td>\n",
       "      <td>2023-06-09 18:36:40+00:00</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7323.0</td>\n",
       "      <td>knn-230609-1829-004-db825a9b</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>2023-06-09 18:35:21+00:00</td>\n",
       "      <td>2023-06-09 18:35:52+00:00</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k  sample_size               TrainingJobName TrainingJobStatus  \\\n",
       "6   8.0       6980.0  knn-230609-1829-003-88f0c586         Completed   \n",
       "8  10.0       6702.0  knn-230609-1829-001-6c106582         Completed   \n",
       "3   9.0       8388.0  knn-230609-1829-006-7338c7f4         Completed   \n",
       "4  10.0       9448.0  knn-230609-1829-005-76c7857c         Completed   \n",
       "1   6.0       7278.0  knn-230609-1829-008-6212a6c0         Completed   \n",
       "7   4.0       8614.0  knn-230609-1829-002-e64bd444         Completed   \n",
       "0   7.0       9788.0  knn-230609-1829-009-04394ea8         Completed   \n",
       "2   5.0       6002.0  knn-230609-1829-007-1ade3091         Completed   \n",
       "5   1.0       7323.0  knn-230609-1829-004-db825a9b         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "6             0.962933 2023-06-09 18:31:17+00:00 2023-06-09 18:34:55+00:00   \n",
       "8             0.962933 2023-06-09 18:31:01+00:00 2023-06-09 18:34:54+00:00   \n",
       "3             0.962769 2023-06-09 18:35:21+00:00 2023-06-09 18:35:52+00:00   \n",
       "4             0.962769 2023-06-09 18:35:23+00:00 2023-06-09 18:35:55+00:00   \n",
       "1             0.962443 2023-06-09 18:36:11+00:00 2023-06-09 18:36:43+00:00   \n",
       "7             0.962443 2023-06-09 18:31:06+00:00 2023-06-09 18:34:54+00:00   \n",
       "0             0.962116 2023-06-09 18:36:18+00:00 2023-06-09 18:36:50+00:00   \n",
       "2             0.958361 2023-06-09 18:36:09+00:00 2023-06-09 18:36:40+00:00   \n",
       "5             0.927825 2023-06-09 18:35:21+00:00 2023-06-09 18:35:52+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "6                       218.0  \n",
       "8                       233.0  \n",
       "3                        31.0  \n",
       "4                        32.0  \n",
       "1                        32.0  \n",
       "7                       228.0  \n",
       "0                        32.0  \n",
       "2                        31.0  \n",
       "5                        31.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_metrics = sagemaker.HyperparameterTuningJobAnalytics(KNN_tuner._current_job_name).dataframe()\n",
    "bayes_metrics.sort_values(['FinalObjectiveValue'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the tuning results, we can pick an optimal parameter combination to build a final model that we can deploy for inference, or we can use the optimal paramater combination as a first round of tuning parameters to inform a secondary round of hyperparamater tuning where ranges could be narrowed down further.   \n",
    "\n",
    "For more information about automatic model tuning, see [Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html). In particular for hyperparameter tuning of Amazon SageMaker KNN's built-in algoritm see \"Part 2: Deep dive, Tuning KNN\" of the kNN notebook sample under \"SageMaker Examples\" from your SageMaker instance top menu - next to 'Files', 'Running', 'Clusters'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
